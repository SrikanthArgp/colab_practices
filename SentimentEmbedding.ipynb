{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19V6oVGKLcBLsX1WorY0hUUOJulUxV_BL",
      "authorship_tag": "ABX9TyM786qReIoE9Tqe2bGnbz80",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrikanthArgp/colab_practices/blob/main/SentimentEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLJb8sj83OqL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sentence_transformers import SentenceTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "ZZ5rPXfo3_wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_file = '/content/drive/MyDrive/AppliedNLPMaterial-master/010_IntroToNLP/data/Tweets.csv'\n",
        "df = pd.read_csv(twitter_file).dropna()\n",
        "df"
      ],
      "metadata": {
        "id": "4i-7MYpB4PhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_id = {'neutral': 1,\n",
        "          'negative': 0,\n",
        "          'positive': 2}\n",
        "\n",
        "df['class'] = df['sentiment'].map(cat_id)"
      ],
      "metadata": {
        "id": "BRe4hmcU4ZMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 150\n",
        "MAX_FEATURES = 10"
      ],
      "metadata": {
        "id": "BtRIWGHM4mQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v1')\n",
        "\n",
        "sentences = [ \"Each sentence is converted\"]\n",
        "embeddings = emb_model.encode(sentences)\n",
        "print(embeddings.squeeze().shape)"
      ],
      "metadata": {
        "id": "fezeIIlY4oKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "CcppifYJ4xkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = emb_model.encode(df['text'].values)"
      ],
      "metadata": {
        "id": "oDJBOVKw5SiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/AppliedNLPMaterial-master/010_IntroToNLP/data/tweets_X.pkl\", \"wb\") as output_file:\n",
        "    pickle.dump(X, output_file)"
      ],
      "metadata": {
        "id": "Dicfahsl5Y_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/AppliedNLPMaterial-master/010_IntroToNLP/data/tweets_X.pkl\", \"rb\") as input_file:\n",
        "    X = pickle.load(input_file)"
      ],
      "metadata": {
        "id": "BOzRosrbHzPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['class'].values"
      ],
      "metadata": {
        "id": "qeuLT86tH_55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=123)"
      ],
      "metadata": {
        "id": "ANDmpEMKIFIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "id": "d0qDpWmnILMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentData(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super().__init__()\n",
        "        self.X = torch.Tensor(X)\n",
        "        self.y = torch.Tensor(y).type(torch.LongTensor)\n",
        "        self.len = len(self.X)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]"
      ],
      "metadata": {
        "id": "OB6EiaG3IP3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = SentimentData(X= X_train, y = y_train)\n",
        "test_ds = SentimentData(X_test, y_test)"
      ],
      "metadata": {
        "id": "t6ucotTiTYGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, batch_size=15000)"
      ],
      "metadata": {
        "id": "i5YhX6c0Te_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentModel(nn.Module):\n",
        "    def __init__(self, NUM_FEATURES, NUM_CLASSES, HIDDEN = 10):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(NUM_FEATURES, HIDDEN)\n",
        "        self.linear2 = nn.Linear(HIDDEN, NUM_CLASSES)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.log_softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "YgHWfAvITi9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentimentModel(NUM_FEATURES = X_train.shape[1], NUM_CLASSES = 3)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters())"
      ],
      "metadata": {
        "id": "K0O0wWb4TpbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "for e in range(NUM_EPOCHS):\n",
        "    curr_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred_log = model(X_batch)\n",
        "        loss = criterion(y_pred_log, y_batch.long())\n",
        "\n",
        "        curr_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    train_losses.append(curr_loss)\n",
        "    print(f\"Epoch {e}, Loss: {curr_loss}\")"
      ],
      "metadata": {
        "id": "4MlcBD3qTsgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lineplot(x=list(range(len(train_losses))), y= train_losses)"
      ],
      "metadata": {
        "id": "ioveOyvFTvcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_test_pred_log = model(X_batch)\n",
        "        y_test_pred = torch.argmax(y_test_pred_log, dim = 1)"
      ],
      "metadata": {
        "id": "XjinJhHtT7IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred_np = y_test_pred.squeeze().cpu().numpy()"
      ],
      "metadata": {
        "id": "a9ljfk2TUAkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = accuracy_score(y_pred=y_test_pred_np, y_true = y_test)\n",
        "f\"The accuracy of the model is {np.round(acc, 3)*100}%.\""
      ],
      "metadata": {
        "id": "4wrkiqVXUEML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_common_cnt = Counter(y_test).most_common()[0][1]\n",
        "print(f\"Naive Classifier: {np.round(most_common_cnt / len(y_test) * 100, 1)} %\")"
      ],
      "metadata": {
        "id": "5bpto2G-UHv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u7NjC8zzUMIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}